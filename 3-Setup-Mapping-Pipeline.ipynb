{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c032f1f7-9845-4669-8160-1691b3342d91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Mapping Pipeline\n",
    "This notebook will deploy the pipeline that performs the mapping from sensor data tables to timestamped RDF triples. We do this to easily incorporate the telemetry data with the model graph defined later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "aed7a27d-8a79-49c4-b2f6-394b490e94e0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import common parameters"
    }
   },
   "outputs": [],
   "source": [
    "%run ./0-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44f3979c-ede4-4941-a379-3c687fd5d1ed",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define pipeline configuration"
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.errors.platform import ResourceConflict\n",
    "from databricks.sdk.service.pipelines import (\n",
    "    PipelineLibrary,\n",
    "    FileLibrary,\n",
    "    PipelinesEnvironment,\n",
    ")\n",
    "\n",
    "w = WorkspaceClient()\n",
    "notebook_path = (\n",
    "    dbutils.notebook.entry_point.getDbutils()\n",
    "    .notebook()\n",
    "    .getContext()\n",
    "    .notebookPath()\n",
    "    .get()\n",
    ")\n",
    "cwd = notebook_path.rsplit(\"/\", 1)[0]\n",
    "\n",
    "pipeline_conf = dict(\n",
    "    name=MAPPING_PIPELINE_NAME,\n",
    "    catalog=TRIPLE_CATALOG,\n",
    "    schema=TRIPLE_SCHEMA,\n",
    "    development=True,\n",
    "    serverless=True,\n",
    "    environment=PipelinesEnvironment(\n",
    "        dependencies=[\"git+https://github.com/aktungmak/spark-r2r.git\"],\n",
    "    ),\n",
    "    libraries=[\n",
    "        PipelineLibrary(\n",
    "            file=FileLibrary(path=cwd + \"/mapping_pipeline/src/dt_mapping.py\")\n",
    "        )\n",
    "    ],\n",
    "    configuration={\n",
    "        \"bundle.sourcePath\": \"./src\",\n",
    "        \"triple_table\": TRIPLE_TABLE,\n",
    "        \"bronze_table\": BRONZE_TABLE,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "006a02fa-c317-40af-ba08-a453b0be9ada",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create the pipeline or update it if it already exists"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    pipeline = w.pipelines.create(allow_duplicate_names=False, **pipeline_conf)\n",
    "    print(f\"Pipeline created with ID: {pipeline.pipeline_id}\")\n",
    "except ResourceConflict:\n",
    "    pipeline = next(w.pipelines.list_pipelines(filter=f\"name LIKE '{MAPPING_PIPELINE_NAME}'\"))\n",
    "    w.pipelines.update(pipeline_id=pipeline.pipeline_id, allow_duplicate_names=False, **pipeline_conf)\n",
    "    print(f\"Updated existing pipeline with ID: {pipeline.pipeline_id} updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "869a6b65-cdac-43a9-a73b-beb757ce930d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Trigger an update"
    }
   },
   "outputs": [],
   "source": [
    "w.pipelines.start_update(pipeline_id=pipeline.pipeline_id)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6575611239363139,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "3-Setup-Mapping-Pipeline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
