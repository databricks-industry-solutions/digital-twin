{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7f065c8-359e-4ce7-a062-957f5ab762f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Create Sensor Bronze Table with Line Data Generator\n",
    "\n",
    "Requires Classic Compute Cluster - DBR >= 16.4 LTS or Serverless with environment version >= 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0068bd63-c5cb-4af8-92ca-e87cc673e69c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "637047ec-881d-46bd-85b4-54e9a6a8ae36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Install custom data generator library\n",
    "%pip install -r ./line_data_generator/requirements.txt\n",
    "%pip install ./line_data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ace668d-b1e6-4b7d-b513-7659a5d4d533",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import common paramters"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run ./0-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4f7eb73-e69c-408d-b937-cef5b1de3063",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 1: Create Delta Table in Unity Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a753edd3-cddd-496e-9269-1962ad5cb3a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Provide required information using the widget at the top of the notebook\n",
    "\n",
    "- Your Unity Catalog table name\n",
    "  - Identify the target table you want to ingest data to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "411534f0-96a9-44fa-b20a-30872a24abed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE TABLE {BRONZE_TABLE} (\n",
    "    sensor_rotation DOUBLE,\n",
    "    sensor_flow DOUBLE,\n",
    "    sensor_temperature DOUBLE,\n",
    "    sensor_speed DOUBLE,\n",
    "    sensor_vibration DOUBLE,\n",
    "    sensor_pressure DOUBLE,\n",
    "    component_yield_output DOUBLE,\n",
    "    timestamp STRING,\n",
    "    component_id STRING,\n",
    "    damaged_component BOOLEAN,\n",
    "    abnormal_sensor STRING,\n",
    "    machine_id STRING,\n",
    "    line_id STRING\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3f3798a-1518-46c1-bb6c-a79022617946",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 2: Generate sensor data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88587f52-be0b-41ea-bfa8-cb1e4fe95691",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We will use a data generator to simulate data coming from a complex ball bearing production system organized as folllwing. \n",
    "\n",
    "The core elements of this prduction system are: \n",
    "- Production Line\n",
    "  - Machine\n",
    "    - Component\n",
    "      - Sensor\n",
    "\n",
    "<br>\n",
    "<img src=\"./images/ball-bearing-diagram.png\" width=\"600\"/>\n",
    "\n",
    "\n",
    "\n",
    "**How does the data generator work**\n",
    "<br>\n",
    "The data genetor will produce data mathing the production line setup you defined in the Digital Twin frontend. The following variables will be used:\n",
    "\n",
    "- Number of lines\n",
    "- Number of machines per line: each line can have a different number of machies.\n",
    "- Number of components per machine: each machine  has the same number of components\n",
    "- Each component has 6 different sensors (fixed) generating data:\n",
    "  - Temperature\n",
    "  - Pressure\n",
    "  - Vibration\n",
    "  - Speed\n",
    "  - Rotation\n",
    "  - Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91b30fc6-625f-4443-87ec-922e2d48b38b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from line_data_generator import generate_all_lines, generate_equipment_mapping, table_size_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9276ecf-02ca-432a-905d-8941a0b2de5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define Production Line configuration -- TODO: Read from config file\n",
    "num_lines = 4\n",
    "machines_per_line = [3, 3, 4, 2]  # Number of machines per line\n",
    "num_components = 3  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "268f9010-0919-4a03-85d1-065376c89689",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<br>You can adjust the size of the generated dataset by setting the sample_size parameter.\n",
    "\n",
    "For instance, if you choose a sample size of 1000, the data generator will produce a dataset with these characteristics:\n",
    "\n",
    "- Each row represents a specific component at a specific timestamp, with component_id and timestamp serving as unique identifiers.\n",
    "- Each component will have 1000 rows, corresponding to the sample size.\n",
    "- Consecutive rows for a given component are spaced 1 millisecond apart. Thus, for a sample size of 1000, the total duration covered per component is 1 second (1000 * 0.001).\n",
    "- The total number of rows in the dataset depends on the number of components in your production line. For example, with 36 components (4 lines, 12 machines, 3 components per machine), the dataset will have 36,000 rows (36 * 1000).\n",
    "- The overall time span for the dataset remains 1 seconds (1000 * 0.001), meaning that sensor data for different components is generated in parallel at the same timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "605dedb5-c642-4e0e-a348-f424f14bc22a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define sample size\n",
    "sample_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05ce3ba4-ddf3-45e9-9990-5d5810594a78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "With this configuration you will generate a dataset with the following size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "351ead65-61b1-4166-95bb-c51e6dc25a63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generate equipment mapping: lines -> machine -> components -> sensors \n",
    "equipment_mapping = generate_equipment_mapping(num_lines, machines_per_line, num_components)\n",
    "\n",
    "# Estimate table size\n",
    "tot_num_rows, est_table_size, line_num_rows, est_line_table_size = table_size_estimator(machines_per_line, num_components, sample_size)\n",
    "\n",
    "print(f\"Number of rows: {tot_num_rows}\")\n",
    "print(f\"Estimated table size: {est_table_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45a294d0-49c1-414b-9257-a296922cf318",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1756298993340}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run data generator and display the first 10 rows\n",
    "batch_df_lines = generate_all_lines(equipment_mapping, sample_size, time.time())\n",
    "display(batch_df_lines.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2922b67e-fe30-4d97-a8a5-36cd1ea9a5a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Write generated data into delta table in UC\n",
    "spark.createDataFrame(batch_df_lines).write.mode(\"append\").saveAsTable(BRONZE_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afd291fa-b719-44ef-823e-3167332e8111",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.table(BRONZE_TABLE).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8781c7f2-f259-47ba-83e5-9b1a9350fad2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "--\n",
    "### _STOP_ - If you want to use Zerobus Ingest to ingest data, go directly to notebook \"2-Ingest-Data-Zerobus\"\n",
    "--\n",
    "### Optional: Simulate Continuous Data Ingestion\n",
    "\n",
    "In this section, we will simulate a continuous data ingestion. To prevent creating a large dataset in a single data generation job, we will run multiple data ingestion batches. Each batch will be generated separately and appended to the Delta Table one at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "428882f8-a3ad-4307-b8dc-c6617a698954",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Define batch configuration\n",
    "\n",
    "sample_size = 10000    # for each sensor\n",
    "batch_count = 5       # number of writes (int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45546226-ef38-4c63-a6fa-5951170273c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "With this configuration you will generate a dataset with the following size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88283e6f-d66a-419b-81cd-9a6399867d9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate total number of rows to be generated \n",
    "tot_num_rows, est_table_size, line_num_rows, est_line_table_size = table_size_estimator(machines_per_line, num_components, sample_size)\n",
    "\n",
    "print(f\"Number of rows in each batch: {tot_num_rows}\")\n",
    "print(f\"Estimated table size in each batch: {est_table_size:.2f} MB\")\n",
    "print(f\"Number of rows for the total dataset: {tot_num_rows * batch_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76f68d4e-77bc-4ef0-9bcc-c507285ac145",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Run the data generator loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20e565d5-a36f-4599-8005-b310bd912a2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run loop to generate data in batch (loop) \n",
    "\n",
    "min_batch_wait =  sample_size *  0.001   # minumun seconds wait between writes to avoid having overlapping time between batches\n",
    "\n",
    "for i in range(0, int(batch_count)):\n",
    "\n",
    "  current_time = time.time()\n",
    "\n",
    "  if i > 0:\n",
    "    if current_time <= batch_time + min_batch_wait:\n",
    "      wait = int(batch_time + min_batch_wait - current_time + 10) # add 10 seconds just in case\n",
    "      time.sleep(wait)\n",
    "      print(f\"Pausing {wait} seconds to avoid overlapping timestamps across batches\")\n",
    "\n",
    "  print(f\"--- Generating batch {int(i+1)} / {int(batch_count)} ---\")\n",
    "\n",
    "  batch_time = time.time()\n",
    "  batch = generate_all_lines(equipment_mapping, sample_size, batch_time)\n",
    "\n",
    "  spark.createDataFrame(batch).write.mode(\"append\").saveAsTable(BRONZE_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c194ecf1-614f-4fa3-a8ca-c0d09b173e9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.table(BRONZE_TABLE).count())"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "1-Create-Sensor-Bronze-Table",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
